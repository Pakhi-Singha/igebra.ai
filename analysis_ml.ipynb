{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af6cf7e7",
   "metadata": {},
   "source": [
    "# Student Cognitive Skills: Analysis, Prediction & Clustering\n",
    "*Generated: 2025-09-18 04:32 UTC*\n",
    "\n",
    "This notebook:\n",
    "1. Loads a synthetic dataset of students\n",
    "2. Explores correlations between cognitive skills and performance\n",
    "3. Trains a model to predict `assessment_score`\n",
    "4. Clusters students into learning personas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('students.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8746e",
   "metadata": {},
   "source": [
    "## Basic Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a45057",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775ee53",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b6017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = ['comprehension','attention','focus','retention','engagement_time','assessment_score']\n",
    "corr = df[numeric_cols].corr()\n",
    "corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.imshow(corr, cmap='viridis', aspect='auto')\n",
    "plt.xticks(range(len(numeric_cols)), numeric_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(numeric_cols)), numeric_cols)\n",
    "plt.colorbar(label='Correlation')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc48151",
   "metadata": {},
   "source": [
    "## Train/Test Split & Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c12974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['comprehension','attention','focus','retention','engagement_time']]\n",
    "y = df['assessment_score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Linear Regression\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)\n",
    "pred_lin = lin.predict(X_test)\n",
    "r2_lin = r2_score(y_test, pred_lin)\n",
    "mae_lin = mean_absolute_error(y_test, pred_lin)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "r2_rf = r2_score(y_test, pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, pred_rf)\n",
    "\n",
    "r2_lin, mae_lin, r2_rf, mae_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb40539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = None\n",
    "try:\n",
    "    importances = rf.feature_importances_\n",
    "    for name, imp in zip(X.columns, importances):\n",
    "        print(f\"{name}: {imp:.3f}\")\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ebbe8e",
   "metadata": {},
   "source": [
    "## Clustering into Learning Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc960a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardize features for clustering\n",
    "features = df[['comprehension','attention','focus','retention','engagement_time']].values\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(features)\n",
    "\n",
    "# Choose k=3 personas for simplicity\n",
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(Z)\n",
    "\n",
    "df['persona'] = labels\n",
    "\n",
    "# Brief semantics (based on cluster centers)\n",
    "centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "centers_df = pd.DataFrame(centroids, columns=['comprehension','attention','focus','retention','engagement_time'])\n",
    "centers_df['size'] = pd.Series([(df['persona']==i).sum() for i in range(3)])\n",
    "centers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7cbd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Map cluster labels to human-friendly persona names based on center ranks\n",
    "def persona_name(row):\n",
    "    # heuristic: weight comprehension & retention higher\n",
    "    score = 0.4*row['comprehension'] + 0.2*row['attention'] + 0.2*row['focus'] + 0.2*row['retention']\n",
    "    if score >= centers_df[['comprehension','attention','focus','retention']].stack().mean():\n",
    "        return 'Focused Achievers'\n",
    "    elif row['engagement_time'] >= centers_df['engagement_time'].mean():\n",
    "        return 'Engaged Strivers'\n",
    "    else:\n",
    "        return 'At-Risk (Low Engagement)'\n",
    "    \n",
    "# Build a mapping cluster_id -> persona label by applying to centers\n",
    "mapping = {}\n",
    "for i in range(3):\n",
    "    mapping[i] = persona_name(centers_df.iloc[i])\n",
    "\n",
    "mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ab603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['persona_name'] = df['persona'].map(mapping)\n",
    "df[['student_id','name','class','assessment_score','persona_name']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871c259e",
   "metadata": {},
   "source": [
    "## Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d97b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save predictions and personas\n",
    "df.to_csv('students_with_personas.csv', index=False)\n",
    "\n",
    "# Save model (best of RF vs Linear)\n",
    "best_model = rf if r2_rf >= r2_lin else lin\n",
    "import pickle\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "with open('scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"Artifacts saved: students_with_personas.csv, model.pkl, scaler.pkl\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
